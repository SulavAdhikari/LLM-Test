{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oElfLGGn5Ngd",
        "outputId": "ed00d732-eb51-4288-b04a-91e350495ebe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gpt3_tokenizer in /usr/local/lib/python3.10/dist-packages (0.1.4)\n",
            "Requirement already satisfied: future<0.19.0,>=0.18.3 in /usr/local/lib/python3.10/dist-packages (from gpt3_tokenizer) (0.18.3)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from gpt3_tokenizer) (2023.12.25)\n",
            "Requirement already satisfied: six<2.0.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from gpt3_tokenizer) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install gpt3_tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZ0keLZt9PWH",
        "outputId": "f2b12d8c-8ad4-4ea2-9196-0d5157ac1bfa"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls drive/MyDrive/llm-test-football-data/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2MxYjmf9ar1",
        "outputId": "58bf137e-2b15-4432-9987-ac9daab0cde6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arsenal.txt\t     Everton.txt\t  Mallorca.txt\t       Real_Madrid.txt\n",
            "Aston_Villa.txt      FIFA.txt\t\t  Manchester_City.txt  Real_Sociedad.txt\n",
            "Athletic_Club.txt    Football.txt\t  Man_City.txt\t       Robert_Lewandowski.txt\n",
            "Atlético_Madrid.txt  Fulham.txt\t\t  Man_United.txt       Sevilla.txt\n",
            "Barcelona.txt\t     Getafe.txt\t\t  Newcastle.txt        Tottenham.txt\n",
            "Brentford.txt\t     Girona.txt\t\t  Nottm_Forest.txt     UEFA_Champions_League.txt\n",
            "Brighton.txt\t     Granada.txt\t  Osasuna.txt\t       UEFA.txt\n",
            "Celta_Vigo.txt\t     Jude_Bellingham.txt  Premiere_League.txt  Valencia.txt\n",
            "Chelsea.txt\t     La_Liga.txt\t  Rayo_Vallecano.txt   Villarreal.txt\n",
            "Crystal_Palace.txt   Liverpool.txt\t  Real_Betis.txt       West_Ham.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gpt3_tokenizer\n",
        "\n",
        "\n",
        "\n",
        "tokenize = lambda s  : gpt3_tokenizer.encode(s)\n",
        "revert = lambda t : gpt3_tokenizer.decode(t)\n",
        "\n",
        "\n",
        "import os\n",
        "# assign directory\n",
        "directory = 'drive/MyDrive/llm-test-football-data/'\n",
        "\n",
        "def get_training_data():\n",
        "\tprint(\"[*]getting data\")\n",
        "\tdata = []\n",
        "\tfor filename in os.listdir(directory):\n",
        "\t\tf = os.path.join(directory, filename)\n",
        "   \t\t# checking if it is a file\n",
        "\t\tif os.path.isfile(f):\n",
        "\t\t\tprint(f)\n",
        "\t\t\tfile = open(f, 'rt')\n",
        "\t\t\tdata.append(tokenize(file.read()))\n",
        "\treturn sum(data, [])\n"
      ],
      "metadata": {
        "id": "z1iuz1SS7tUb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model"
      ],
      "metadata": {
        "id": "3ZtUKQIM7v1u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, GRU, Embedding\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint"
      ],
      "metadata": {
        "id": "9UCDyJak7yPZ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = get_training_data()\n",
        "\n",
        "tokens = sorted(list(set(training_data)))\n",
        "mapping = dict((c, i) for i, c in enumerate(tokens))\n",
        "\n",
        "def create_seq(text):\n",
        "    length = 30\n",
        "    sequences = list()\n",
        "    for i in range(length, len(text)):\n",
        "        # select sequence of tokens\n",
        "        seq = text[i-length:i+1]\n",
        "        # store\n",
        "        sequences.append(seq)\n",
        "    print('Total Sequences: %d' % len(sequences))\n",
        "    return sequences\n",
        "\n",
        "# create sequences\n",
        "sequences = create_seq(training_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvU38gG87zaL",
        "outputId": "d686c490-1ddd-4452-9188-005e0eedf83c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*]getting data\n",
            "drive/MyDrive/llm-test-football-data/Football.txt\n",
            "drive/MyDrive/llm-test-football-data/La_Liga.txt\n",
            "drive/MyDrive/llm-test-football-data/Real_Madrid.txt\n",
            "drive/MyDrive/llm-test-football-data/Barcelona.txt\n",
            "drive/MyDrive/llm-test-football-data/Athletic_Club.txt\n",
            "drive/MyDrive/llm-test-football-data/Girona.txt\n",
            "drive/MyDrive/llm-test-football-data/Atlético_Madrid.txt\n",
            "drive/MyDrive/llm-test-football-data/Real_Sociedad.txt\n",
            "drive/MyDrive/llm-test-football-data/Real_Betis.txt\n",
            "drive/MyDrive/llm-test-football-data/Valencia.txt\n",
            "drive/MyDrive/llm-test-football-data/Getafe.txt\n",
            "drive/MyDrive/llm-test-football-data/Villarreal.txt\n",
            "drive/MyDrive/llm-test-football-data/Osasuna.txt\n",
            "drive/MyDrive/llm-test-football-data/Sevilla.txt\n",
            "drive/MyDrive/llm-test-football-data/Celta_Vigo.txt\n",
            "drive/MyDrive/llm-test-football-data/Mallorca.txt\n",
            "drive/MyDrive/llm-test-football-data/Rayo_Vallecano.txt\n",
            "drive/MyDrive/llm-test-football-data/Granada.txt\n",
            "drive/MyDrive/llm-test-football-data/Premiere_League.txt\n",
            "drive/MyDrive/llm-test-football-data/Arsenal.txt\n",
            "drive/MyDrive/llm-test-football-data/Liverpool.txt\n",
            "drive/MyDrive/llm-test-football-data/Man_City.txt\n",
            "drive/MyDrive/llm-test-football-data/Manchester_City.txt\n",
            "drive/MyDrive/llm-test-football-data/Aston_Villa.txt\n",
            "drive/MyDrive/llm-test-football-data/Tottenham.txt\n",
            "drive/MyDrive/llm-test-football-data/Man_United.txt\n",
            "drive/MyDrive/llm-test-football-data/West_Ham.txt\n",
            "drive/MyDrive/llm-test-football-data/Brighton.txt\n",
            "drive/MyDrive/llm-test-football-data/Newcastle.txt\n",
            "drive/MyDrive/llm-test-football-data/Fulham.txt\n",
            "drive/MyDrive/llm-test-football-data/Chelsea.txt\n",
            "drive/MyDrive/llm-test-football-data/Brentford.txt\n",
            "drive/MyDrive/llm-test-football-data/Crystal_Palace.txt\n",
            "drive/MyDrive/llm-test-football-data/Everton.txt\n",
            "drive/MyDrive/llm-test-football-data/Nottm_Forest.txt\n",
            "drive/MyDrive/llm-test-football-data/UEFA_Champions_League.txt\n",
            "drive/MyDrive/llm-test-football-data/UEFA.txt\n",
            "drive/MyDrive/llm-test-football-data/FIFA.txt\n",
            "drive/MyDrive/llm-test-football-data/Jude_Bellingham.txt\n",
            "drive/MyDrive/llm-test-football-data/Robert_Lewandowski.txt\n",
            "Total Sequences: 306461\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# vocabulary size\n",
        "vocab = len(mapping)\n",
        "sequences = np.array(sequences)\n",
        "# create X and y\n",
        "X, y = sequences[:,:-1], sequences[:,-1]\n",
        "# one hot encode y\n",
        "y = to_categorical(y )\n",
        "# create train and validation sets\n",
        "X_tr, X_val, y_tr, y_val = train_test_split(X, y, test_size=0.1, random_state=42)\n",
        "\n",
        "print('Train shape:', X_tr.shape, 'Val shape:', X_val.shape)"
      ],
      "metadata": {
        "id": "_OS-bZFG771E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab, 50, input_length=30, trainable=True))\n",
        "model.add(GRU(150, recurrent_dropout=0.1, dropout=0.1))\n",
        "model.add(Dense(vocab, activation='softmax'))\n",
        "print(model.summary())\n",
        "\n",
        "# compile the model\n",
        "model.compile(loss='categorical_crossentropy', metrics=['acc'], optimizer='adam')\n",
        "# fit the model\n",
        "model.fit(X_tr, y_tr, epochs=100, verbose=2, validation_data=(X_val, y_val))"
      ],
      "metadata": {
        "id": "NCnYfrWr_lzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_seq(model, mapping, seq_length, seed_text, n_chars):\n",
        "\tin_text = seed_text\n",
        "\t# generate a fixed number of characters\n",
        "\tfor _ in range(n_chars):\n",
        "\t\t# encode the characters as integers\n",
        "\t\tencoded = [mapping[char] for char in in_text]\n",
        "\t\t# truncate sequences to a fixed length\n",
        "\t\tencoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
        "\t\t# predict character\n",
        "\t\tyhat = model.predict_classes(encoded, verbose=0)\n",
        "\t\t# reverse map integer to character\n",
        "\t\tout_char = ''\n",
        "\t\tfor char, index in mapping.items():\n",
        "\t\t\tif index == yhat:\n",
        "\t\t\t\tout_char = char\n",
        "\t\t\t\tbreak\n",
        "\t\t# append to input\n",
        "\t\tin_text += char\n",
        "\treturn in_text"
      ],
      "metadata": {
        "id": "dlQGrzha7-M9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "yJkye1cN51kt"
      }
    }
  ]
}